{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75c4c59b-b208-46fa-8c2f-836a3924ef2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_out_super | Epoch 1: Train Acc=0.9131 | Val Acc=0.9883\n",
      "✅ Model saved to model_out_super\n",
      "model_out_super | Epoch 2: Train Acc=0.9945 | Val Acc=0.9903\n",
      "✅ Model saved to model_out_super\n",
      "model_out_super | Epoch 3: Train Acc=0.9960 | Val Acc=0.9901\n",
      "model_out_super | Epoch 4: Train Acc=0.9967 | Val Acc=0.9923\n",
      "✅ Model saved to model_out_super\n",
      "model_out_super | Epoch 5: Train Acc=0.9989 | Val Acc=0.9909\n",
      "model_out_super | Epoch 6: Train Acc=0.9979 | Val Acc=0.9896\n",
      "model_out_super | Epoch 7: Train Acc=0.9972 | Val Acc=0.9916\n",
      "model_out_super | Epoch 8: Train Acc=0.9994 | Val Acc=0.9929\n",
      "✅ Model saved to model_out_super\n",
      "model_out_super | Epoch 9: Train Acc=0.9988 | Val Acc=0.9874\n",
      "model_out_super | Epoch 10: Train Acc=0.9990 | Val Acc=0.9912\n",
      "model_out_super | Epoch 11: Train Acc=0.9991 | Val Acc=0.9916\n",
      "model_out_super | Epoch 12: Train Acc=0.9990 | Val Acc=0.9912\n",
      "model_out_super | Epoch 13: Train Acc=0.9995 | Val Acc=0.9909\n",
      "model_out_super | Epoch 14: Train Acc=0.9996 | Val Acc=0.9876\n",
      "model_out_super | Epoch 15: Train Acc=0.9990 | Val Acc=0.9901\n",
      "model_out_cat | Epoch 1: Train Acc=0.8119 | Val Acc=0.9792\n",
      "✅ Model saved to model_out_cat\n",
      "model_out_cat | Epoch 2: Train Acc=0.9880 | Val Acc=0.9858\n",
      "✅ Model saved to model_out_cat\n",
      "model_out_cat | Epoch 3: Train Acc=0.9935 | Val Acc=0.9856\n",
      "model_out_cat | Epoch 4: Train Acc=0.9963 | Val Acc=0.9858\n",
      "model_out_cat | Epoch 5: Train Acc=0.9967 | Val Acc=0.9883\n",
      "✅ Model saved to model_out_cat\n",
      "model_out_cat | Epoch 6: Train Acc=0.9982 | Val Acc=0.9876\n",
      "model_out_cat | Epoch 7: Train Acc=0.9975 | Val Acc=0.9879\n",
      "model_out_cat | Epoch 8: Train Acc=0.9984 | Val Acc=0.9870\n",
      "model_out_cat | Epoch 9: Train Acc=0.9987 | Val Acc=0.9852\n",
      "model_out_cat | Epoch 10: Train Acc=0.9987 | Val Acc=0.9859\n",
      "model_out_cat | Epoch 11: Train Acc=0.9985 | Val Acc=0.9879\n",
      "model_out_cat | Epoch 12: Train Acc=0.9994 | Val Acc=0.9856\n",
      "model_out_cat | Epoch 13: Train Acc=0.9988 | Val Acc=0.9878\n",
      "model_out_cat | Epoch 14: Train Acc=0.9996 | Val Acc=0.9878\n",
      "model_out_cat | Epoch 15: Train Acc=0.9994 | Val Acc=0.9885\n",
      "✅ Model saved to model_out_cat\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import csv\n",
    "import warnings\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# =============================\n",
    "# Config\n",
    "# =============================\n",
    "MODEL_PATH = \"atipiqal/bert-italian-cased-civil\"  # HF model\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 16\n",
    "LR = 2e-5\n",
    "VAL_SPLIT = 0.2\n",
    "SEED = 42\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_DIR_SUP = \"model_out_super\"\n",
    "MODEL_DIR_CAT = \"model_out_cat\"\n",
    "os.makedirs(MODEL_DIR_SUP, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR_CAT, exist_ok=True)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# =============================\n",
    "# Load dataset\n",
    "# =============================\n",
    "df = pd.read_csv(\"data/dataset.csv\", sep=\";\", quoting=csv.QUOTE_MINIMAL, encoding=\"utf-8\")\n",
    "df = df.rename(columns=lambda c: c.strip().upper())\n",
    "df = df[[\"DESCRIZIONE\", \"SUPERCATEGORIA\", \"CATEGORIA\"]].dropna()\n",
    "\n",
    "# Maps\n",
    "supers = sorted(df[\"SUPERCATEGORIA\"].unique())\n",
    "cats = sorted(df[\"CATEGORIA\"].unique())\n",
    "sup2idx = {s: i for i, s in enumerate(supers)}\n",
    "cat2idx = {c: i for i, c in enumerate(cats)}\n",
    "idx2sup = {i: s for s, i in sup2idx.items()}\n",
    "idx2cat = {i: c for c, i in cat2idx.items()}\n",
    "\n",
    "# Dataset classes\n",
    "class SupDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, records):\n",
    "        self.records = records\n",
    "    def __len__(self): return len(self.records)\n",
    "    def __getitem__(self, idx):\n",
    "        r = self.records[idx]\n",
    "        return r[\"DESCRIZIONE\"], sup2idx[r[\"SUPERCATEGORIA\"]]\n",
    "\n",
    "class CatDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, records):\n",
    "        self.records = records\n",
    "    def __len__(self): return len(self.records)\n",
    "    def __getitem__(self, idx):\n",
    "        r = self.records[idx]\n",
    "        return r[\"DESCRIZIONE\"], cat2idx[r[\"CATEGORIA\"]]\n",
    "\n",
    "# Shuffle records\n",
    "records = df.to_dict(\"records\")\n",
    "random.seed(SEED)\n",
    "random.shuffle(records)\n",
    "\n",
    "# =============================\n",
    "# Model class\n",
    "# =============================\n",
    "class ClassifierModel(nn.Module):\n",
    "    def __init__(self, model_path, nlabels):\n",
    "        super().__init__()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        self.encoder = AutoModel.from_pretrained(model_path, add_pooling_layer=False)\n",
    "        dim = self.encoder.config.hidden_size\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(dim, 256), nn.ReLU(), nn.Dropout(0.2), nn.Linear(256, nlabels)\n",
    "        )\n",
    "\n",
    "    def forward(self, texts):\n",
    "        texts = [\"descrizione tecnica: \" + t for t in texts]\n",
    "        tokens = self.tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").to(DEVICE)\n",
    "        output = self.encoder(**tokens)\n",
    "        emb = output.last_hidden_state[:, 0]\n",
    "        return self.head(emb)\n",
    "\n",
    "# =============================\n",
    "# Generic training function\n",
    "# =============================\n",
    "def train_model(model, train_dl, val_dl, loss_fn, model_dir, idx2label):\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "    best_acc = 0\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        total, correct = 0, 0\n",
    "        for texts, labels in train_dl:\n",
    "            labels = labels.to(DEVICE)\n",
    "            opt.zero_grad()\n",
    "            out = model(texts)\n",
    "            loss = loss_fn(out, labels)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total += labels.size(0)\n",
    "            correct += (out.argmax(dim=1) == labels).sum().item()\n",
    "        acc_train = correct / total\n",
    "\n",
    "        model.eval()\n",
    "        total, correct = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for texts, labels in val_dl:\n",
    "                labels = labels.to(DEVICE)\n",
    "                out = model(texts)\n",
    "                total += labels.size(0)\n",
    "                correct += (out.argmax(dim=1) == labels).sum().item()\n",
    "        acc_val = correct / total\n",
    "        print(f\"{model_dir} | Epoch {epoch+1}: Train Acc={acc_train:.4f} | Val Acc={acc_val:.4f}\")\n",
    "\n",
    "        if acc_val > best_acc:\n",
    "            best_acc = acc_val\n",
    "            torch.save(model.state_dict(), os.path.join(model_dir, \"best_model.pt\"))\n",
    "            print(f\"✅ Model saved to {model_dir}\")\n",
    "\n",
    "    # Save label mappings\n",
    "    with open(os.path.join(model_dir, \"label_mappings.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        for i, lbl in idx2label.items():\n",
    "            f.write(f\"{i}: {lbl}\\n\")\n",
    "\n",
    "# =============================\n",
    "# Train SUPERCATEGORIA model\n",
    "# =============================\n",
    "sup_ds = SupDataset(records)\n",
    "val_size = int(len(sup_ds) * VAL_SPLIT)\n",
    "train_size = len(sup_ds) - val_size\n",
    "train_sup, val_sup = random_split(sup_ds, [train_size, val_size])\n",
    "train_sup_dl = DataLoader(train_sup, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_sup_dl = DataLoader(val_sup, batch_size=BATCH_SIZE)\n",
    "\n",
    "sup_counts = torch.tensor(np.bincount([sup2idx[r[\"SUPERCATEGORIA\"]] for r in records]), dtype=torch.float)\n",
    "weight_sup = 1.0 / sup_counts\n",
    "loss_sup = nn.CrossEntropyLoss(weight=weight_sup.to(DEVICE))\n",
    "\n",
    "sup_model = ClassifierModel(MODEL_PATH, len(supers)).to(DEVICE)\n",
    "train_model(sup_model, train_sup_dl, val_sup_dl, loss_sup, MODEL_DIR_SUP, idx2sup)\n",
    "\n",
    "# =============================\n",
    "# Train CATEGORIA model\n",
    "# =============================\n",
    "cat_ds = CatDataset(records)\n",
    "val_size = int(len(cat_ds) * VAL_SPLIT)\n",
    "train_size = len(cat_ds) - val_size\n",
    "train_cat, val_cat = random_split(cat_ds, [train_size, val_size])\n",
    "train_cat_dl = DataLoader(train_cat, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_cat_dl = DataLoader(val_cat, batch_size=BATCH_SIZE)\n",
    "\n",
    "cat_counts = torch.tensor(np.bincount([cat2idx[r[\"CATEGORIA\"]] for r in records]), dtype=torch.float)\n",
    "weight_cat = 1.0 / cat_counts\n",
    "loss_cat = nn.CrossEntropyLoss(weight=weight_cat.to(DEVICE))\n",
    "\n",
    "cat_model = ClassifierModel(MODEL_PATH, len(cats)).to(DEVICE)\n",
    "train_model(cat_model, train_cat_dl, val_cat_dl, loss_cat, MODEL_DIR_CAT, idx2cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1a9779-f70c-4817-9074-0e18789e960b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
